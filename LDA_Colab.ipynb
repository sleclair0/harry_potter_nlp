{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "LDA_Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sleclair0/harry_potter_nlp/blob/master/LDA_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GAc9GHcrW06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjLAyuVHzRg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/foo.txt'\n",
        "%cd /gdrive\n",
        "%cd 'My Drive'\n",
        "%cd 'Colab Notebooks'\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72MR0YR30rQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw_dppNYpT60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "from pprint import pprint\n",
        "\n",
        "# Set Pandas to display all rows of dataframes\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu0v4VHTu2nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g5SFzKJpiJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "data_dir = '/data'\n",
        "if not os.path.exists(data_dir):\n",
        "  os.makedirs(data_dir)\n",
        "%ls data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKr9g9n0twF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8N2aLi12eWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_list = gdrive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc4vqmxKpT63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "books = [\"/gdrive/My Drive/Colab Notebooks/data/HP2_chap2.txt\",\n",
        "        \"/gdrive/My Drive/Colab Notebooks/data/HP7_epilogue.txt\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaGm21QhpT65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = (\"(C H A P T E R (?:[A-Z-][ ]){2,}[A-Z]|\"\n",
        "           \"E P I L O G U E)\\s+\" +                   # Group 1 selects the chapter number\n",
        "           \"([A-Z \\n',.-]+)\\\\b(?![A-Z]+(?=\\.)\\\\b)\" + # Group 2 selects the chapter title but excludes all caps word beginning first sentence of the chapter\n",
        "           \"(?![a-z']|[A-Z.])\" +                     # chapter title ends before lowercase letters or a period\n",
        "           \"(.*?)\" +                                 # Group 3 selects the chapter contents\n",
        "           \"(?=C H A P T E R (?:[A-Z][ ]){2,}|\"\n",
        "           \"This\\s+book\\s+was\\s+art\\s+directed\\s+|\"\n",
        "           \"E P I L O G U E)\")                       # chapter contents ends with a new chapter, epilogue or the end of book\n",
        "hp = defaultdict(dict)\n",
        "ibook = 0    \n",
        "\n",
        "for book in books:\n",
        "    print(book)\n",
        "    title = book[38:-4]\n",
        "    print(title)\n",
        "    with open(book, 'r') as f:\n",
        "        text = (f.read().replace('&rsquo;', \"'\")\n",
        "                        .replace('&lsquo;', \"'\")\n",
        "                        .replace('&rdquo;', '\"')\n",
        "                        .replace('&ldquo;', '\"')\n",
        "                        .replace('&mdash;', 'â€”'))\n",
        "    #chapters = re.findall(pattern, text, re.DOTALL)\n",
        "    print(len(text))\n",
        "    ibook = ibook + 1    \n",
        "    if ibook == 1:\n",
        "      hp['book 2 Harry Potter and the Chamber of Secrets']['Chapter 2'] = (\"DOBBY'S WARNING\", text)\n",
        "\n",
        "    if ibook == 2:\n",
        "      hp['book 7 Harry Potter and the Deathly Hallows']['Epilogue'] = ('Epilogue', text)\n",
        "\n",
        "    '''\n",
        "    for chapter in chapters:\n",
        "        chap += 1\n",
        "        chap_title = chapter[1].replace('\\n','')\n",
        "        chap_text = chapter[2][3:]\n",
        "        phrase = ' HE-WHO-MUST-NOT-BE-NAMED RETURNS'\n",
        "        if phrase in chap_title:\n",
        "            chap_title = chap_title.replace(phrase, '')\n",
        "            chap_text = phrase[1:] + ' I' + chap_text\n",
        "        chap_text = re.sub('\\n*&bull; [0-9]+ &bull; \\n*' + chap_title + ' \\n*', '', chap_text, flags=re.IGNORECASE)\n",
        "        chap_text = re.sub('\\n*&bull; [0-9]+ &bull;\\s*(CHAPTER [A-Z-]+\\s*)|(EPILOGUE)\\s*', '', chap_text)\n",
        "        chap_text = re.sub(' \\n&bull; [0-9]+ &bull; \\n*', '', chap_text)\n",
        "        chap_text = re.sub('\\s*'.join([word for word in chap_title.split()]), '', chap_text)\n",
        "        hp[title]['Chapter ' + str(chap)] = (chap_title, chap_text)\n",
        "     '''\n",
        "hp = dict(hp)\n",
        "#hp[\"Harry Potter and the Deathly Hallows\"]['Epilogue'] = hp[\"Harry Potter and the Deathly Hallows\"].pop('Chapter 37')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q5WXCfApT66",
        "colab_type": "text"
      },
      "source": [
        "### The format of the Harry Potter hp dictionary is as follows:\n",
        "&nbsp;   \n",
        "{book 1 title: {  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'Chapter 1': (chapter title, chapter text),  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'Chapter 2': (chapter title, chapter text),  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'Chapter 3': (chapter title, chapter text),  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ...  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }  \n",
        " 'book 2 title': {  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'Chapter 1': (chapter title, chapter text),  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ...  \n",
        "         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }  \n",
        " &nbsp;...  \n",
        "}  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBySXkkG9_u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(books)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH2N2bg4pT67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Word Count\n",
        "for book in hp:\n",
        "    print('{:,} words in {}'.format(sum(len(hp[book][chapter][1].split()) for chapter in hp[book]), book))\n",
        "print()    \n",
        "print('{:,} total words in collection'.format(sum(len(hp[book][chapter][1].split())\n",
        "                                                for book in hp\n",
        "                                                for chapter in hp[book])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqhJv0eDpT6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average word length\n",
        "for book in hp:\n",
        "    text = ''\n",
        "    for chapter in hp[book]:\n",
        "        text = text + hp[book][chapter][1]\n",
        "    print('{:.2f} Average word length in {}'.format(len(text) / len(text.split()), book))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obEyeIScpT7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chapters in books\n",
        "for book in hp:\n",
        "    chapters = 0\n",
        "    for chapter in hp[book]:\n",
        "        chapters += 1\n",
        "    print('{} chapters in {}'.format(chapters, book))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9UjMdDZpT7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')# NLTK Stop words\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "# stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz29aERYpT7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to list\n",
        "data = [hp[book][chapter][1].replace('\\n', '') for book in hp for chapter in hp[book]]\n",
        "print(data[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN4gA5zIpT7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYnsJCIApT7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sfk56RxpT7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc])# if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M1zy9kapT7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3jn12O8pT7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(data_lemmatized))\n",
        "print(data_lemmatized[0])\n",
        "print(data_lemmatized[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iqOCvj6wpT7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVwZX0sppT7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAMhFNtJpT7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qE078z_kpT7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the Keyword in the 20 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB6UtESLpT7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "print ('Perplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print ('Coherence Score: ', coherence_lda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqveT1jFpT7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "pyLDAvis.display(vis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohplD9W-JyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JA5mrC0_YpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get -qq install -y libarchive-dev && pip install -q -U libarchive\n",
        "import libarchive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY90QpEN_dBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('mallet-2.0.8.zip', 'rb') as f:\n",
        "    for entry in libarchive.public.memory_pour(f.read()):\n",
        "        print(entry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYkFf0Dg_7rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip mallet-2.0.8.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_1Zq9bpT7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3znGdigZpT7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Topics\n",
        "pprint(ldamallet.show_topics(num_topics=1000, formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz6FViEZpT7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        print('Calculating {}-topic model'.format(num_topics))\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFUH2jSdpT7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can take a long time to run.\n",
        "limit=35; start=2; step=1;\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word,\n",
        "                                                        corpus=corpus,\n",
        "                                                        texts=data_lemmatized,\n",
        "                                                        start=start,\n",
        "                                                        limit=limit,\n",
        "                                                        step=step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urj5ki9apT7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show graph\n",
        "x = range(start, limit, step)\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "# plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgADtU_5pT71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmtviI0TpT74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the model and print the topics\n",
        "index, value = max(enumerate(coherence_values), key=operator.itemgetter(1))\n",
        "index = 10\n",
        "optimal_model = model_list[index]\n",
        "model_topics = optimal_model.show_topics(num_topics=1000, formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj4sJefJpT78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimal_model.show_topic(0,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zji4bFTLpT8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for topic in sorted(optimal_model.show_topics(num_topics=1000, num_words=10, formatted=False), key=lambda x: x[0]):\n",
        "    print('Topic {}: {}'.format(topic[0], [item[0] for item in topic[1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jg-uqS3pT8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkwRZvjGpT8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dominant_topic[df_dominant_topic['Dominant_Topic'].isin([0, 1])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAwgzOIypT8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[text.split() for text in df_dominant_topic['Keywords'].tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVFBnRJRpT8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, row in df_dominant_topic.iterrows():\n",
        "    print('{}. Dominant keywords: {}'.format(row['Document_No'], row['Keywords'].split(', ')[:5]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRGAMk2MpT8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Show\n",
        "sent_topics_sorteddf_mallet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xiDDpPngpT8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, row in sent_topics_sorteddf_mallet.iterrows():\n",
        "    print('Topic number {}'.format(int(row['Topic_Num'])))\n",
        "    print('Keywords: {}'.format(row['Keywords']))\n",
        "    print()\n",
        "    print(row['Text'])\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr4_A2DlpT8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = sent_topics_sorteddf_mallet[['Topic_Num', 'Keywords']]\n",
        "\n",
        "# Concatenate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Percent_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzdCAJp4pT8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "    pd.set_option('display.max_colwidth', -1)\n",
        "    display(df_dominant_topics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EfGWODupT8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dominant_topics.to_csv('df_dominant_topics.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcDaYj65pT8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk5AXvVbpT8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeGRHKMHpT8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv8y9V-bpT8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDdOe5yWpT8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltbj2fEypT8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r88WB5FzpT8p",
        "colab_type": "text"
      },
      "source": [
        "# LDA using individual sentences as documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2mQ0boFpT8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaIO1Es8pT8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to list\n",
        "data = []\n",
        "for book in hp:\n",
        "    for chapter in hp[book]:\n",
        "        data.extend(tokenize.sent_tokenize(hp[book][chapter][1].replace('\\n', '')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGEbD71qpT8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to list\n",
        "print('Creating corpus')\n",
        "data = []\n",
        "for book in hp:\n",
        "    for chapter in hp[book]:\n",
        "        data.extend(tokenize.sent_tokenize(hp[book][chapter][1].replace('\\n', '')))\n",
        "\n",
        "# Tokenize into words\n",
        "print('Tokenizing')\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "# Build the bigram and trigram models\n",
        "print('Creating bigrams and trigrams')\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "print('Building bigram and trigram models')\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# Remove Stop Words\n",
        "print('Removing stopwords')\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "print('Forming bigrams')\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "print('Lemmatizing')\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "# Create Dictionary\n",
        "print('Creating dictionary')\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "print('Creating corpus')\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "print('Creating term frequency list')\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6ArxeX6pT8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC-I3-YupT8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can take a long time to run.\n",
        "limit=35; start=2; step=1;\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word,\n",
        "                                                        corpus=corpus,\n",
        "                                                        texts=data_lemmatized,\n",
        "                                                        start=start,\n",
        "                                                        limit=limit,\n",
        "                                                        step=step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz6iG2zdpT80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show graph\n",
        "x = range(start, limit, step)\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "# plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOzvzpzwpT82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-j5kPR4pT84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the model and print the topics\n",
        "index, value = max(enumerate(coherence_values), key=operator.itemgetter(1))\n",
        "index = 6\n",
        "optimal_model = model_list[index]\n",
        "model_topics = optimal_model.show_topics(num_topics=1000, formatted=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ILTp5HpT86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=8, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "\n",
        "# Compute Perplexity\n",
        "print ('Perplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print ('Coherence Score: ', coherence_lda)\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "pyLDAvis.display(vis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do864OrapT88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for topic in sorted(optimal_model.show_topics(num_topics=1000, num_words=10, formatted=False), key=lambda x: x[0]):\n",
        "    print('Topic {}: {}'.format(topic[0], [item[0] for item in topic[1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXeBRbIbpT8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4jiczlqpT9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = sent_topics_sorteddf_mallet[['Topic_Num', 'Keywords']]\n",
        "\n",
        "# Concatenate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Percent_Documents']\n",
        "\n",
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRHKilf3pT9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "    pd.set_option('display.max_colwidth', -1)\n",
        "    display(df_dominant_topics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqf2cWOYpT9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}